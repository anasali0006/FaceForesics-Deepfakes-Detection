{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training.ipynb",
      "provenance": [],
      "mount_file_id": "1aitKm0CdIIXs2z7CDg4kwKWaYRmG6k48",
      "authorship_tag": "ABX9TyOl7VU0E3N1CuAzo4bMmdAh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anasali0006/FaceForesics-Deepfakes-Detection/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkbsAwzLFep4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "#import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import PIL\n",
        "import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETNFi904_84h"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Hk7PgjzHRFp"
      },
      "source": [
        "GPU Status"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znEpyVxfHQ1C"
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4VtSmGPHjfh",
        "outputId": "41c5f0f0-ace7-4851-ccf6-38693731e248"
      },
      "source": [
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.8 GB  | Proc size: 113.0 MB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bIPl0WBHxe0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa7agDieFw7A"
      },
      "source": [
        "**Getting the video data from drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjjCi75QFwMP"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/ML-DeepFakes-Detection/saved-arrays /content/video_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIwhKbUvIcEY"
      },
      "source": [
        "#load real images\n",
        "dir='/content/video_data/'\n",
        "real='real'\n",
        "fake='fake'\n",
        "real_array=np.zeros((1,100,100,3))\n",
        "for i in range(1,25):\n",
        "  dir_real=dir + real + str(i)\n",
        "  with open(dir_real, 'rb') as f:\n",
        "    new_array = pickle.load(f)\n",
        "  truncated_array = new_array[1:,:,:,:]\n",
        "  real_array=np.append(real_array, truncated_array, axis=0)\n",
        "  \n",
        "real_array=real_array[1:,:,:,:]\n",
        "  # Python 3: open(..., 'rb')\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBRbRC4usXnM"
      },
      "source": [
        "#load fake images\n",
        "dir='/content/video_data/'\n",
        "real='real'\n",
        "fake='fake'\n",
        "fake_array=np.zeros((1,100,100,3))\n",
        "for i in range(1,25):\n",
        "  dir_fake=dir + fake + str(i)\n",
        "  with open(dir_fake, 'rb') as f:\n",
        "    new_array = pickle.load(f)\n",
        "  truncated_array = new_array[1:,:,:,:]\n",
        "  fake_array=np.append(fake_array, truncated_array, axis=0)\n",
        "  \n",
        "fake_array=fake_array[1:,:,:,:]\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4twL0vP3fyCa"
      },
      "source": [
        "**Preprocessing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQStzlOuvNh0"
      },
      "source": [
        "#real images are labelled 1\n",
        "#fake images are labelled 0\n",
        "\n",
        "real_label=np.ones((len(real_array)))\n",
        "fake_label=np.zeros((len(fake_array)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3oMvnWm9Glx"
      },
      "source": [
        "train_examples=np.vstack([real_array, fake_array])\n",
        "train_labels0=np.hstack([real_label, fake_label])\n",
        "train_labels=tf.keras.utils.to_categorical(train_labels0, num_classes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fjSTayL7NCh",
        "outputId": "42dc487c-9261-4f37-b2d9-a06defe5c2c2"
      },
      "source": [
        "print(train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " ...\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnjk4f0rA893"
      },
      "source": [
        "#delete the redundant variables to free up ram\n",
        "del(real_array)\n",
        "del(fake_array)\n",
        "del(real_label)\n",
        "del(fake_label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kIc5i3ogag_"
      },
      "source": [
        "**Converting numpy arrays into Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8ikREo5S_79"
      },
      "source": [
        "train_tensor_examples=tf.convert_to_tensor(train_examples)\n",
        "train_tensor_labels=tf.convert_to_tensor(train_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5C63LzVTgBJ",
        "outputId": "297efc1b-c07e-45c5-f09c-4b6420bf4364"
      },
      "source": [
        "train_tensor_labels.get_shape()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([11106, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265qgpk3giIL"
      },
      "source": [
        "**Creating Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhyU-d8-3Nm2"
      },
      "source": [
        "#converting to tf.data.Dataset format\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_tensor_examples, train_tensor_labels))\n",
        "#train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS3FMLQGCUI_"
      },
      "source": [
        "del(train_labels0)\n",
        "del(train_examples)\n",
        "del(train_labels)\n",
        "del(train_tensor_examples)\n",
        "del(train_tensor_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJTrpNe3gqXe"
      },
      "source": [
        "**Shuffling the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoO2iTyA-nsQ"
      },
      "source": [
        "train_dataset=train_dataset.shuffle(buffer_size=1000, seed=123 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc1O5DpRguMI"
      },
      "source": [
        "**Creating Validation and Train split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiJU6LZCPbhR"
      },
      "source": [
        "#make validation and training split\n",
        "#taking 1000 images for validation\n",
        "val_data=train_dataset.take(1000)\n",
        "train_dataset=train_dataset.skip(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTLTJwIggovI"
      },
      "source": [
        "**Creating Batches**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBRDSJyNHPtR"
      },
      "source": [
        "train_dataset=train_dataset.batch(batch_size=32)\n",
        "val_data=val_data.batch(32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOoNmHThAvh6",
        "outputId": "65f90319-dd71-460b-de23-f5ebbb6811e7"
      },
      "source": [
        "#checking the shapes of dataset\n",
        "for x, y in train_dataset:\n",
        "  print (x.shape)\n",
        "  print (y.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 100, 100, 3)\n",
            "(32, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbtFdtu1g_4y"
      },
      "source": [
        "**Visualizing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIF-sQhYHvGS"
      },
      "source": [
        "#visualizing the data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title([labels[i]])\n",
        "    plt.axis(\"off\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "wpaF-9WZajST",
        "outputId": "d99fc7b2-b84b-4b1f-c9fe-48eabaab6eb4"
      },
      "source": [
        "cv2_imshow(images[5].numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=100x100 at 0x7F44B1A88278>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etLWvu8dhEKn"
      },
      "source": [
        "**Importing the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCnjoynJcalD",
        "outputId": "f53c140e-fdff-4de9-9620-84e6f47e96e2"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "base_model=Xception( include_top=False, weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLLO-UoHiojs",
        "outputId": "8e0c8bd1-d9dc-4698-a33e-b2d60548ecac"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 1 512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_36 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 2 32768       add_36[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 2 1024        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_37 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 7 186368      add_37[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 7 2912        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_38 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_39 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_38[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_40 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_39[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_41 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_40[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_42 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_41[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_43 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_42[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_44 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_43[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_45 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_44[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_46 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_45[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 1 745472      add_46[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 1 4096        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_47 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_47[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 20,806,952\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h27C071NoNdx",
        "outputId": "5a7bf8e0-f2ac-4bd9-e6ad-cf478b886854"
      },
      "source": [
        "len(base_model.layers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEJIUOi-rU30"
      },
      "source": [
        "Set all the layers to non trainable except the final layer. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmowTUI1qIez"
      },
      "source": [
        "base_model.trainable=False\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKc2dcyrqvh0",
        "outputId": "5ed01c8c-b4b7-49d8-d6dc-a7982b8d69c2"
      },
      "source": [
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"xception\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, None, None, 1 512         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 2 32768       add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 2 1024        conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 7 186368      add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 7 2912        conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 1 745472      add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 1 4096        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 0\n",
            "Non-trainable params: 20,861,480\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU0lrqFAtrsg"
      },
      "source": [
        "**Model Graph**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBy3e8UdrrNg"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "input = Input(shape=(100,100,3))\n",
        "\n",
        "x = Rescaling(1./255) (input)\n",
        "x = base_model(x, training=True)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "output = Dense(2, activation='softmax') (x)\n",
        "\n",
        "model=tf.keras.Model(input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OR9JB4b8b-K",
        "outputId": "2453c2d7-a659-4071-8881-2ac8bd8616fc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
            "_________________________________________________________________\n",
            "rescaling_4 (Rescaling)      (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, None, None, 2048)  20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 20,865,578\n",
            "Trainable params: 4,098\n",
            "Non-trainable params: 20,861,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYhfmJD39sNX"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXO038yW9vQ8"
      },
      "source": [
        "rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSE7Cbwz96ey"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt= Adam(learning_rate=0.002)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52n0gN5K-ScT"
      },
      "source": [
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJxm0HdX_BAN"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCwx-hZm-vmy",
        "outputId": "61b23617-61e5-4a31-b9bf-3647bd893300"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data=val_data,\n",
        "          batch_size=32,\n",
        "          epochs=3,  \n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "316/316 [==============================] - 23s 43ms/step - loss: 0.1552 - accuracy: 0.9557 - val_loss: 6.9160 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/3\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.6802 - accuracy: 0.8601 - val_loss: 7.4239 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/3\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.6895 - accuracy: 0.8580 - val_loss: 7.5109 - val_accuracy: 0.0010\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faf3e1123c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsSUtimz_g6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca5ca88-8e51-4ad3-bff6-4fbce88780c5"
      },
      "source": [
        "base_model.trainable=True\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
            "_________________________________________________________________\n",
            "rescaling (Rescaling)        (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "xception (Functional)        (None, None, None, 2048)  20861480  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 4098      \n",
            "=================================================================\n",
            "Total params: 20,865,578\n",
            "Trainable params: 20,811,050\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W41HZd6Wqs_j"
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"/content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create a callback that saves the model's weights every 5 epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=50*316)\n",
        "\n",
        "\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NkGJjeupDnOH",
        "outputId": "3e1a359e-c8d4-41bd-ebee-710c56a36389"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data=val_data,\n",
        "          batch_size=32,\n",
        "          epochs=500,  \n",
        "          callbacks=[cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.0959 - accuracy: 0.9723 - val_loss: 5.3000 - val_accuracy: 0.1630\n",
            "Epoch 2/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.1424 - accuracy: 0.9619 - val_loss: 5.6834 - val_accuracy: 0.1580\n",
            "Epoch 3/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.1392 - accuracy: 0.9661 - val_loss: 5.3210 - val_accuracy: 0.1850\n",
            "Epoch 4/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1349 - accuracy: 0.9656 - val_loss: 5.9924 - val_accuracy: 0.1580\n",
            "Epoch 5/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.1537 - accuracy: 0.9643 - val_loss: 5.7114 - val_accuracy: 0.1800\n",
            "Epoch 6/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.1519 - accuracy: 0.9629 - val_loss: 5.5588 - val_accuracy: 0.1760\n",
            "Epoch 7/500\n",
            "316/316 [==============================] - 12s 37ms/step - loss: 0.1389 - accuracy: 0.9643 - val_loss: 5.3271 - val_accuracy: 0.1810\n",
            "Epoch 8/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1395 - accuracy: 0.9630 - val_loss: 5.0638 - val_accuracy: 0.1970\n",
            "Epoch 9/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1339 - accuracy: 0.9663 - val_loss: 5.4576 - val_accuracy: 0.1640\n",
            "Epoch 10/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1354 - accuracy: 0.9653 - val_loss: 5.3817 - val_accuracy: 0.1710\n",
            "Epoch 11/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1325 - accuracy: 0.9672 - val_loss: 5.0555 - val_accuracy: 0.2080\n",
            "Epoch 12/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1487 - accuracy: 0.9647 - val_loss: 5.0194 - val_accuracy: 0.1980\n",
            "Epoch 13/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1196 - accuracy: 0.9660 - val_loss: 5.1429 - val_accuracy: 0.2030\n",
            "Epoch 14/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1414 - accuracy: 0.9632 - val_loss: 5.2073 - val_accuracy: 0.2040\n",
            "Epoch 15/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1287 - accuracy: 0.9663 - val_loss: 5.3361 - val_accuracy: 0.1930\n",
            "Epoch 16/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1351 - accuracy: 0.9654 - val_loss: 4.9054 - val_accuracy: 0.2160\n",
            "Epoch 17/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1251 - accuracy: 0.9670 - val_loss: 5.0427 - val_accuracy: 0.2050\n",
            "Epoch 18/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1311 - accuracy: 0.9665 - val_loss: 4.7963 - val_accuracy: 0.2190\n",
            "Epoch 19/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1187 - accuracy: 0.9701 - val_loss: 4.9671 - val_accuracy: 0.2210\n",
            "Epoch 20/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 5.0956 - val_accuracy: 0.2090\n",
            "Epoch 21/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1357 - accuracy: 0.9664 - val_loss: 5.2777 - val_accuracy: 0.2030\n",
            "Epoch 22/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1436 - accuracy: 0.9644 - val_loss: 5.0547 - val_accuracy: 0.2010\n",
            "Epoch 23/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1290 - accuracy: 0.9673 - val_loss: 4.8139 - val_accuracy: 0.2080\n",
            "Epoch 24/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1209 - accuracy: 0.9678 - val_loss: 5.1032 - val_accuracy: 0.2110\n",
            "Epoch 25/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1245 - accuracy: 0.9705 - val_loss: 4.7771 - val_accuracy: 0.2370\n",
            "Epoch 26/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1261 - accuracy: 0.9697 - val_loss: 4.8300 - val_accuracy: 0.2320\n",
            "Epoch 27/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1312 - accuracy: 0.9682 - val_loss: 4.6424 - val_accuracy: 0.2360\n",
            "Epoch 28/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1227 - accuracy: 0.9670 - val_loss: 4.9217 - val_accuracy: 0.2340\n",
            "Epoch 29/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1264 - accuracy: 0.9710 - val_loss: 4.8310 - val_accuracy: 0.2240\n",
            "Epoch 30/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1167 - accuracy: 0.9695 - val_loss: 4.4017 - val_accuracy: 0.2510\n",
            "Epoch 31/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1256 - accuracy: 0.9704 - val_loss: 4.9620 - val_accuracy: 0.2200\n",
            "Epoch 32/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1339 - accuracy: 0.9671 - val_loss: 4.3890 - val_accuracy: 0.2760\n",
            "Epoch 33/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1143 - accuracy: 0.9701 - val_loss: 4.4954 - val_accuracy: 0.2490\n",
            "Epoch 34/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1165 - accuracy: 0.9709 - val_loss: 4.5860 - val_accuracy: 0.2480\n",
            "Epoch 35/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1145 - accuracy: 0.9692 - val_loss: 4.8137 - val_accuracy: 0.2200\n",
            "Epoch 36/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1173 - accuracy: 0.9702 - val_loss: 4.3633 - val_accuracy: 0.2600\n",
            "Epoch 37/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1273 - accuracy: 0.9695 - val_loss: 4.4672 - val_accuracy: 0.2620\n",
            "Epoch 38/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1203 - accuracy: 0.9680 - val_loss: 4.8605 - val_accuracy: 0.2380\n",
            "Epoch 39/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1208 - accuracy: 0.9712 - val_loss: 5.0078 - val_accuracy: 0.2190\n",
            "Epoch 40/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1185 - accuracy: 0.9693 - val_loss: 5.0684 - val_accuracy: 0.2160\n",
            "Epoch 41/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1253 - accuracy: 0.9700 - val_loss: 4.4218 - val_accuracy: 0.2590\n",
            "Epoch 42/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1168 - accuracy: 0.9697 - val_loss: 4.5499 - val_accuracy: 0.2500\n",
            "Epoch 43/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1197 - accuracy: 0.9682 - val_loss: 4.3255 - val_accuracy: 0.2540\n",
            "Epoch 44/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1102 - accuracy: 0.9712 - val_loss: 4.3131 - val_accuracy: 0.2680\n",
            "Epoch 45/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0979 - accuracy: 0.9724 - val_loss: 4.3896 - val_accuracy: 0.2760\n",
            "Epoch 46/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1091 - accuracy: 0.9703 - val_loss: 4.5547 - val_accuracy: 0.2470\n",
            "Epoch 47/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1084 - accuracy: 0.9686 - val_loss: 4.7323 - val_accuracy: 0.2370\n",
            "Epoch 48/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1010 - accuracy: 0.9730 - val_loss: 4.8889 - val_accuracy: 0.2360\n",
            "Epoch 49/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1174 - accuracy: 0.9683 - val_loss: 4.4536 - val_accuracy: 0.2580\n",
            "Epoch 50/500\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.1142 - accuracy: 0.9701\n",
            "Epoch 00050: saving model to /content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-0050.ckpt\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.1139 - accuracy: 0.9702 - val_loss: 4.0680 - val_accuracy: 0.2930\n",
            "Epoch 51/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1050 - accuracy: 0.9733 - val_loss: 4.6301 - val_accuracy: 0.2360\n",
            "Epoch 52/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1082 - accuracy: 0.9738 - val_loss: 5.1149 - val_accuracy: 0.2130\n",
            "Epoch 53/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1189 - accuracy: 0.9712 - val_loss: 4.1549 - val_accuracy: 0.3010\n",
            "Epoch 54/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1083 - accuracy: 0.9726 - val_loss: 4.8066 - val_accuracy: 0.2210\n",
            "Epoch 55/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1163 - accuracy: 0.9717 - val_loss: 4.4920 - val_accuracy: 0.2590\n",
            "Epoch 56/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1086 - accuracy: 0.9720 - val_loss: 5.0453 - val_accuracy: 0.2210\n",
            "Epoch 57/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1102 - accuracy: 0.9726 - val_loss: 4.9168 - val_accuracy: 0.2410\n",
            "Epoch 58/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1095 - accuracy: 0.9727 - val_loss: 4.4965 - val_accuracy: 0.2810\n",
            "Epoch 59/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1117 - accuracy: 0.9717 - val_loss: 4.3282 - val_accuracy: 0.2620\n",
            "Epoch 60/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1032 - accuracy: 0.9730 - val_loss: 4.2431 - val_accuracy: 0.2920\n",
            "Epoch 61/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1000 - accuracy: 0.9751 - val_loss: 4.2619 - val_accuracy: 0.2950\n",
            "Epoch 62/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1103 - accuracy: 0.9709 - val_loss: 4.3678 - val_accuracy: 0.2910\n",
            "Epoch 63/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1139 - accuracy: 0.9694 - val_loss: 4.3490 - val_accuracy: 0.2720\n",
            "Epoch 64/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1128 - accuracy: 0.9707 - val_loss: 3.8797 - val_accuracy: 0.3130\n",
            "Epoch 65/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1098 - accuracy: 0.9722 - val_loss: 4.1347 - val_accuracy: 0.3080\n",
            "Epoch 66/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1069 - accuracy: 0.9730 - val_loss: 4.2073 - val_accuracy: 0.2770\n",
            "Epoch 67/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.1047 - accuracy: 0.9728 - val_loss: 3.8830 - val_accuracy: 0.3380\n",
            "Epoch 68/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0956 - accuracy: 0.9746 - val_loss: 4.0474 - val_accuracy: 0.3050\n",
            "Epoch 69/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0998 - accuracy: 0.9741 - val_loss: 4.1516 - val_accuracy: 0.2850\n",
            "Epoch 70/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1041 - accuracy: 0.9727 - val_loss: 4.2971 - val_accuracy: 0.2720\n",
            "Epoch 71/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1084 - accuracy: 0.9725 - val_loss: 4.6398 - val_accuracy: 0.2510\n",
            "Epoch 72/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1015 - accuracy: 0.9717 - val_loss: 5.1721 - val_accuracy: 0.2180\n",
            "Epoch 73/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1133 - accuracy: 0.9713 - val_loss: 3.8913 - val_accuracy: 0.3260\n",
            "Epoch 74/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1177 - accuracy: 0.9706 - val_loss: 3.8353 - val_accuracy: 0.3260\n",
            "Epoch 75/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0943 - accuracy: 0.9730 - val_loss: 3.9574 - val_accuracy: 0.3180\n",
            "Epoch 76/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1006 - accuracy: 0.9745 - val_loss: 3.9409 - val_accuracy: 0.3050\n",
            "Epoch 77/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0944 - accuracy: 0.9741 - val_loss: 4.0041 - val_accuracy: 0.3210\n",
            "Epoch 78/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0960 - accuracy: 0.9727 - val_loss: 4.6409 - val_accuracy: 0.2820\n",
            "Epoch 79/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1042 - accuracy: 0.9745 - val_loss: 4.0590 - val_accuracy: 0.3250\n",
            "Epoch 80/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1040 - accuracy: 0.9727 - val_loss: 3.9574 - val_accuracy: 0.3120\n",
            "Epoch 81/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0882 - accuracy: 0.9761 - val_loss: 4.1551 - val_accuracy: 0.3020\n",
            "Epoch 82/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0988 - accuracy: 0.9722 - val_loss: 3.9955 - val_accuracy: 0.3290\n",
            "Epoch 83/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0947 - accuracy: 0.9744 - val_loss: 3.9245 - val_accuracy: 0.3330\n",
            "Epoch 84/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0963 - accuracy: 0.9754 - val_loss: 4.1784 - val_accuracy: 0.2920\n",
            "Epoch 85/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1022 - accuracy: 0.9749 - val_loss: 4.2051 - val_accuracy: 0.2910\n",
            "Epoch 86/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1014 - accuracy: 0.9729 - val_loss: 4.1432 - val_accuracy: 0.3060\n",
            "Epoch 87/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0973 - accuracy: 0.9731 - val_loss: 4.1444 - val_accuracy: 0.2880\n",
            "Epoch 88/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0940 - accuracy: 0.9750 - val_loss: 3.9551 - val_accuracy: 0.3120\n",
            "Epoch 89/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0940 - accuracy: 0.9749 - val_loss: 4.3284 - val_accuracy: 0.2880\n",
            "Epoch 90/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1030 - accuracy: 0.9739 - val_loss: 4.1504 - val_accuracy: 0.3100\n",
            "Epoch 91/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0909 - accuracy: 0.9759 - val_loss: 4.2833 - val_accuracy: 0.3030\n",
            "Epoch 92/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1078 - accuracy: 0.9750 - val_loss: 3.8647 - val_accuracy: 0.3210\n",
            "Epoch 93/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0945 - accuracy: 0.9757 - val_loss: 3.9055 - val_accuracy: 0.3170\n",
            "Epoch 94/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0894 - accuracy: 0.9774 - val_loss: 3.9635 - val_accuracy: 0.3200\n",
            "Epoch 95/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0947 - accuracy: 0.9758 - val_loss: 4.1531 - val_accuracy: 0.3040\n",
            "Epoch 96/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0945 - accuracy: 0.9746 - val_loss: 4.1787 - val_accuracy: 0.3010\n",
            "Epoch 97/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0931 - accuracy: 0.9757 - val_loss: 4.1115 - val_accuracy: 0.3350\n",
            "Epoch 98/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1003 - accuracy: 0.9751 - val_loss: 4.0853 - val_accuracy: 0.3150\n",
            "Epoch 99/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0933 - accuracy: 0.9752 - val_loss: 4.0861 - val_accuracy: 0.3120\n",
            "Epoch 100/500\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.0960 - accuracy: 0.9745\n",
            "Epoch 00100: saving model to /content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-0100.ckpt\n",
            "316/316 [==============================] - 13s 41ms/step - loss: 0.0958 - accuracy: 0.9746 - val_loss: 4.1805 - val_accuracy: 0.3170\n",
            "Epoch 101/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0962 - accuracy: 0.9755 - val_loss: 4.2619 - val_accuracy: 0.3050\n",
            "Epoch 102/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1014 - accuracy: 0.9738 - val_loss: 3.8438 - val_accuracy: 0.3360\n",
            "Epoch 103/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0999 - accuracy: 0.9764 - val_loss: 3.5402 - val_accuracy: 0.3650\n",
            "Epoch 104/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0907 - accuracy: 0.9769 - val_loss: 3.7030 - val_accuracy: 0.3500\n",
            "Epoch 105/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1019 - accuracy: 0.9741 - val_loss: 3.9233 - val_accuracy: 0.3230\n",
            "Epoch 106/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0852 - accuracy: 0.9764 - val_loss: 4.1665 - val_accuracy: 0.3100\n",
            "Epoch 107/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1068 - accuracy: 0.9717 - val_loss: 3.7247 - val_accuracy: 0.3620\n",
            "Epoch 108/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0841 - accuracy: 0.9764 - val_loss: 3.6522 - val_accuracy: 0.3640\n",
            "Epoch 109/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0882 - accuracy: 0.9770 - val_loss: 4.0751 - val_accuracy: 0.3200\n",
            "Epoch 110/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0918 - accuracy: 0.9778 - val_loss: 3.2037 - val_accuracy: 0.4050\n",
            "Epoch 111/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0771 - accuracy: 0.9794 - val_loss: 3.5579 - val_accuracy: 0.3640\n",
            "Epoch 112/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0901 - accuracy: 0.9764 - val_loss: 3.4679 - val_accuracy: 0.3610\n",
            "Epoch 113/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0930 - accuracy: 0.9749 - val_loss: 4.0326 - val_accuracy: 0.3200\n",
            "Epoch 114/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0850 - accuracy: 0.9764 - val_loss: 4.0555 - val_accuracy: 0.3060\n",
            "Epoch 115/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.1026 - accuracy: 0.9753 - val_loss: 3.5086 - val_accuracy: 0.3700\n",
            "Epoch 116/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0898 - accuracy: 0.9744 - val_loss: 3.8365 - val_accuracy: 0.3300\n",
            "Epoch 117/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0914 - accuracy: 0.9757 - val_loss: 3.6794 - val_accuracy: 0.3490\n",
            "Epoch 118/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0849 - accuracy: 0.9778 - val_loss: 3.8450 - val_accuracy: 0.3470\n",
            "Epoch 119/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0867 - accuracy: 0.9773 - val_loss: 3.6650 - val_accuracy: 0.3460\n",
            "Epoch 120/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0839 - accuracy: 0.9765 - val_loss: 3.5756 - val_accuracy: 0.3520\n",
            "Epoch 121/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0847 - accuracy: 0.9777 - val_loss: 4.0718 - val_accuracy: 0.3140\n",
            "Epoch 122/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0911 - accuracy: 0.9761 - val_loss: 3.4037 - val_accuracy: 0.3850\n",
            "Epoch 123/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0861 - accuracy: 0.9783 - val_loss: 3.5699 - val_accuracy: 0.3760\n",
            "Epoch 124/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0896 - accuracy: 0.9758 - val_loss: 3.6202 - val_accuracy: 0.3410\n",
            "Epoch 125/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0865 - accuracy: 0.9767 - val_loss: 3.6550 - val_accuracy: 0.3660\n",
            "Epoch 126/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0868 - accuracy: 0.9759 - val_loss: 3.7343 - val_accuracy: 0.3410\n",
            "Epoch 127/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0934 - accuracy: 0.9764 - val_loss: 3.7422 - val_accuracy: 0.3540\n",
            "Epoch 128/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0846 - accuracy: 0.9779 - val_loss: 3.7966 - val_accuracy: 0.3470\n",
            "Epoch 129/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0857 - accuracy: 0.9771 - val_loss: 3.9557 - val_accuracy: 0.3320\n",
            "Epoch 130/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0944 - accuracy: 0.9771 - val_loss: 3.4162 - val_accuracy: 0.3780\n",
            "Epoch 131/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0775 - accuracy: 0.9794 - val_loss: 3.3090 - val_accuracy: 0.3950\n",
            "Epoch 132/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0856 - accuracy: 0.9764 - val_loss: 3.0930 - val_accuracy: 0.4260\n",
            "Epoch 133/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0803 - accuracy: 0.9764 - val_loss: 3.2263 - val_accuracy: 0.3950\n",
            "Epoch 134/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0867 - accuracy: 0.9764 - val_loss: 3.1729 - val_accuracy: 0.4030\n",
            "Epoch 135/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0846 - accuracy: 0.9772 - val_loss: 3.1499 - val_accuracy: 0.4000\n",
            "Epoch 136/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0777 - accuracy: 0.9777 - val_loss: 4.2007 - val_accuracy: 0.3080\n",
            "Epoch 137/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0918 - accuracy: 0.9768 - val_loss: 3.2542 - val_accuracy: 0.3970\n",
            "Epoch 138/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0857 - accuracy: 0.9781 - val_loss: 3.7369 - val_accuracy: 0.3330\n",
            "Epoch 139/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0906 - accuracy: 0.9770 - val_loss: 3.2357 - val_accuracy: 0.3920\n",
            "Epoch 140/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0828 - accuracy: 0.9779 - val_loss: 3.8022 - val_accuracy: 0.3410\n",
            "Epoch 141/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.1003 - accuracy: 0.9740 - val_loss: 3.6767 - val_accuracy: 0.3470\n",
            "Epoch 142/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0777 - accuracy: 0.9791 - val_loss: 3.6265 - val_accuracy: 0.3690\n",
            "Epoch 143/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0785 - accuracy: 0.9789 - val_loss: 3.8386 - val_accuracy: 0.3300\n",
            "Epoch 144/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0803 - accuracy: 0.9783 - val_loss: 3.6772 - val_accuracy: 0.3510\n",
            "Epoch 145/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0832 - accuracy: 0.9785 - val_loss: 3.4156 - val_accuracy: 0.3710\n",
            "Epoch 146/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0751 - accuracy: 0.9790 - val_loss: 3.5011 - val_accuracy: 0.3860\n",
            "Epoch 147/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0833 - accuracy: 0.9770 - val_loss: 3.3804 - val_accuracy: 0.3920\n",
            "Epoch 148/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0853 - accuracy: 0.9783 - val_loss: 3.8374 - val_accuracy: 0.3490\n",
            "Epoch 149/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0809 - accuracy: 0.9785 - val_loss: 4.2319 - val_accuracy: 0.3090\n",
            "Epoch 150/500\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9776\n",
            "Epoch 00150: saving model to /content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-0150.ckpt\n",
            "316/316 [==============================] - 13s 41ms/step - loss: 0.0871 - accuracy: 0.9776 - val_loss: 3.6312 - val_accuracy: 0.3510\n",
            "Epoch 151/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0812 - accuracy: 0.9782 - val_loss: 3.3838 - val_accuracy: 0.3940\n",
            "Epoch 152/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0884 - accuracy: 0.9774 - val_loss: 3.7423 - val_accuracy: 0.3500\n",
            "Epoch 153/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0797 - accuracy: 0.9795 - val_loss: 3.4381 - val_accuracy: 0.3840\n",
            "Epoch 154/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0889 - accuracy: 0.9779 - val_loss: 3.3456 - val_accuracy: 0.3970\n",
            "Epoch 155/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0824 - accuracy: 0.9775 - val_loss: 3.5192 - val_accuracy: 0.3640\n",
            "Epoch 156/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0800 - accuracy: 0.9797 - val_loss: 3.4460 - val_accuracy: 0.3790\n",
            "Epoch 157/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0752 - accuracy: 0.9792 - val_loss: 3.5073 - val_accuracy: 0.3630\n",
            "Epoch 158/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0762 - accuracy: 0.9782 - val_loss: 3.7959 - val_accuracy: 0.3480\n",
            "Epoch 159/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0860 - accuracy: 0.9775 - val_loss: 3.3730 - val_accuracy: 0.4030\n",
            "Epoch 160/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0791 - accuracy: 0.9778 - val_loss: 3.5776 - val_accuracy: 0.3610\n",
            "Epoch 161/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0902 - accuracy: 0.9767 - val_loss: 3.3564 - val_accuracy: 0.3850\n",
            "Epoch 162/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0830 - accuracy: 0.9775 - val_loss: 3.2673 - val_accuracy: 0.3830\n",
            "Epoch 163/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0860 - accuracy: 0.9773 - val_loss: 3.3490 - val_accuracy: 0.3830\n",
            "Epoch 164/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0849 - accuracy: 0.9797 - val_loss: 3.6403 - val_accuracy: 0.3570\n",
            "Epoch 165/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0871 - accuracy: 0.9779 - val_loss: 3.6566 - val_accuracy: 0.3500\n",
            "Epoch 166/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0860 - accuracy: 0.9778 - val_loss: 3.6213 - val_accuracy: 0.3620\n",
            "Epoch 167/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0892 - accuracy: 0.9765 - val_loss: 3.3206 - val_accuracy: 0.3740\n",
            "Epoch 168/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0716 - accuracy: 0.9799 - val_loss: 3.3847 - val_accuracy: 0.3850\n",
            "Epoch 169/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0753 - accuracy: 0.9800 - val_loss: 3.5019 - val_accuracy: 0.3750\n",
            "Epoch 170/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0784 - accuracy: 0.9787 - val_loss: 3.2604 - val_accuracy: 0.3980\n",
            "Epoch 171/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0766 - accuracy: 0.9797 - val_loss: 3.3731 - val_accuracy: 0.3920\n",
            "Epoch 172/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0770 - accuracy: 0.9795 - val_loss: 3.4165 - val_accuracy: 0.3810\n",
            "Epoch 173/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0826 - accuracy: 0.9801 - val_loss: 2.8852 - val_accuracy: 0.4340\n",
            "Epoch 174/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0766 - accuracy: 0.9787 - val_loss: 3.2910 - val_accuracy: 0.3710\n",
            "Epoch 175/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0833 - accuracy: 0.9800 - val_loss: 2.9957 - val_accuracy: 0.4240\n",
            "Epoch 176/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0728 - accuracy: 0.9796 - val_loss: 3.1683 - val_accuracy: 0.4150\n",
            "Epoch 177/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0768 - accuracy: 0.9786 - val_loss: 3.1150 - val_accuracy: 0.4000\n",
            "Epoch 178/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0883 - accuracy: 0.9800 - val_loss: 3.1646 - val_accuracy: 0.4100\n",
            "Epoch 179/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0724 - accuracy: 0.9801 - val_loss: 3.3342 - val_accuracy: 0.3710\n",
            "Epoch 180/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0783 - accuracy: 0.9769 - val_loss: 3.8457 - val_accuracy: 0.3500\n",
            "Epoch 181/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0877 - accuracy: 0.9774 - val_loss: 3.4193 - val_accuracy: 0.3640\n",
            "Epoch 182/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0789 - accuracy: 0.9807 - val_loss: 3.0422 - val_accuracy: 0.4010\n",
            "Epoch 183/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0735 - accuracy: 0.9782 - val_loss: 3.2861 - val_accuracy: 0.3840\n",
            "Epoch 184/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0749 - accuracy: 0.9792 - val_loss: 3.2939 - val_accuracy: 0.3920\n",
            "Epoch 185/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0725 - accuracy: 0.9797 - val_loss: 2.9834 - val_accuracy: 0.4360\n",
            "Epoch 186/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0688 - accuracy: 0.9806 - val_loss: 3.2203 - val_accuracy: 0.3930\n",
            "Epoch 187/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0799 - accuracy: 0.9796 - val_loss: 3.1889 - val_accuracy: 0.4060\n",
            "Epoch 188/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0740 - accuracy: 0.9787 - val_loss: 3.3937 - val_accuracy: 0.3920\n",
            "Epoch 189/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0793 - accuracy: 0.9781 - val_loss: 3.3834 - val_accuracy: 0.3860\n",
            "Epoch 190/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0813 - accuracy: 0.9781 - val_loss: 3.0696 - val_accuracy: 0.4030\n",
            "Epoch 191/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0753 - accuracy: 0.9790 - val_loss: 3.0755 - val_accuracy: 0.4170\n",
            "Epoch 192/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0746 - accuracy: 0.9795 - val_loss: 3.1595 - val_accuracy: 0.4150\n",
            "Epoch 193/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0684 - accuracy: 0.9816 - val_loss: 3.5530 - val_accuracy: 0.3680\n",
            "Epoch 194/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0811 - accuracy: 0.9818 - val_loss: 3.3982 - val_accuracy: 0.3800\n",
            "Epoch 195/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0719 - accuracy: 0.9806 - val_loss: 3.2722 - val_accuracy: 0.3840\n",
            "Epoch 196/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0720 - accuracy: 0.9800 - val_loss: 3.2020 - val_accuracy: 0.4020\n",
            "Epoch 197/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0779 - accuracy: 0.9783 - val_loss: 2.8432 - val_accuracy: 0.4450\n",
            "Epoch 198/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0755 - accuracy: 0.9806 - val_loss: 3.1022 - val_accuracy: 0.4060\n",
            "Epoch 199/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0783 - accuracy: 0.9792 - val_loss: 2.5865 - val_accuracy: 0.4560\n",
            "Epoch 200/500\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9812\n",
            "Epoch 00200: saving model to /content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-0200.ckpt\n",
            "316/316 [==============================] - 13s 41ms/step - loss: 0.0664 - accuracy: 0.9813 - val_loss: 2.8087 - val_accuracy: 0.4310\n",
            "Epoch 201/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0658 - accuracy: 0.9823 - val_loss: 2.9296 - val_accuracy: 0.4300\n",
            "Epoch 202/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0727 - accuracy: 0.9800 - val_loss: 2.9558 - val_accuracy: 0.4160\n",
            "Epoch 203/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0746 - accuracy: 0.9799 - val_loss: 3.3464 - val_accuracy: 0.3840\n",
            "Epoch 204/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0755 - accuracy: 0.9800 - val_loss: 3.0981 - val_accuracy: 0.3970\n",
            "Epoch 205/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0761 - accuracy: 0.9795 - val_loss: 3.0356 - val_accuracy: 0.4090\n",
            "Epoch 206/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0706 - accuracy: 0.9811 - val_loss: 2.9282 - val_accuracy: 0.4370\n",
            "Epoch 207/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0810 - accuracy: 0.9781 - val_loss: 3.2915 - val_accuracy: 0.3880\n",
            "Epoch 208/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0718 - accuracy: 0.9818 - val_loss: 3.0098 - val_accuracy: 0.4250\n",
            "Epoch 209/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0712 - accuracy: 0.9802 - val_loss: 3.2320 - val_accuracy: 0.3890\n",
            "Epoch 210/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0809 - accuracy: 0.9780 - val_loss: 2.9324 - val_accuracy: 0.4330\n",
            "Epoch 211/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0682 - accuracy: 0.9813 - val_loss: 2.8179 - val_accuracy: 0.4490\n",
            "Epoch 212/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0680 - accuracy: 0.9809 - val_loss: 2.7519 - val_accuracy: 0.4550\n",
            "Epoch 213/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0651 - accuracy: 0.9806 - val_loss: 3.0184 - val_accuracy: 0.4120\n",
            "Epoch 214/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0698 - accuracy: 0.9820 - val_loss: 2.9348 - val_accuracy: 0.4440\n",
            "Epoch 215/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0758 - accuracy: 0.9789 - val_loss: 3.1699 - val_accuracy: 0.3950\n",
            "Epoch 216/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0730 - accuracy: 0.9799 - val_loss: 2.8891 - val_accuracy: 0.4240\n",
            "Epoch 217/500\n",
            "316/316 [==============================] - 13s 39ms/step - loss: 0.0631 - accuracy: 0.9819 - val_loss: 3.2939 - val_accuracy: 0.3860\n",
            "Epoch 218/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0699 - accuracy: 0.9823 - val_loss: 3.1423 - val_accuracy: 0.4160\n",
            "Epoch 219/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0718 - accuracy: 0.9807 - val_loss: 2.7725 - val_accuracy: 0.4600\n",
            "Epoch 220/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0709 - accuracy: 0.9804 - val_loss: 2.9754 - val_accuracy: 0.4390\n",
            "Epoch 221/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0662 - accuracy: 0.9814 - val_loss: 2.9534 - val_accuracy: 0.4170\n",
            "Epoch 222/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0697 - accuracy: 0.9817 - val_loss: 3.0999 - val_accuracy: 0.4320\n",
            "Epoch 223/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0699 - accuracy: 0.9803 - val_loss: 3.2132 - val_accuracy: 0.4050\n",
            "Epoch 224/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0750 - accuracy: 0.9807 - val_loss: 3.4765 - val_accuracy: 0.3960\n",
            "Epoch 225/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0905 - accuracy: 0.9791 - val_loss: 2.7217 - val_accuracy: 0.4680\n",
            "Epoch 226/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0650 - accuracy: 0.9813 - val_loss: 2.4558 - val_accuracy: 0.5020\n",
            "Epoch 227/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0625 - accuracy: 0.9817 - val_loss: 3.0445 - val_accuracy: 0.4240\n",
            "Epoch 228/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0732 - accuracy: 0.9806 - val_loss: 3.0016 - val_accuracy: 0.4400\n",
            "Epoch 229/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0737 - accuracy: 0.9804 - val_loss: 2.7954 - val_accuracy: 0.4570\n",
            "Epoch 230/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0763 - accuracy: 0.9802 - val_loss: 3.0827 - val_accuracy: 0.4270\n",
            "Epoch 231/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0731 - accuracy: 0.9807 - val_loss: 3.1304 - val_accuracy: 0.4170\n",
            "Epoch 232/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0687 - accuracy: 0.9814 - val_loss: 3.1118 - val_accuracy: 0.4150\n",
            "Epoch 233/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0680 - accuracy: 0.9797 - val_loss: 2.5957 - val_accuracy: 0.4700\n",
            "Epoch 234/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0617 - accuracy: 0.9827 - val_loss: 2.9001 - val_accuracy: 0.4420\n",
            "Epoch 235/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0714 - accuracy: 0.9796 - val_loss: 3.1624 - val_accuracy: 0.4020\n",
            "Epoch 236/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0687 - accuracy: 0.9826 - val_loss: 3.1590 - val_accuracy: 0.4180\n",
            "Epoch 237/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0718 - accuracy: 0.9812 - val_loss: 3.0191 - val_accuracy: 0.4210\n",
            "Epoch 238/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0771 - accuracy: 0.9822 - val_loss: 2.3229 - val_accuracy: 0.5180\n",
            "Epoch 239/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0586 - accuracy: 0.9830 - val_loss: 2.9953 - val_accuracy: 0.4170\n",
            "Epoch 240/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0745 - accuracy: 0.9795 - val_loss: 3.1220 - val_accuracy: 0.4110\n",
            "Epoch 241/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0744 - accuracy: 0.9795 - val_loss: 2.8546 - val_accuracy: 0.4310\n",
            "Epoch 242/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0718 - accuracy: 0.9803 - val_loss: 2.6448 - val_accuracy: 0.4760\n",
            "Epoch 243/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0668 - accuracy: 0.9798 - val_loss: 3.1232 - val_accuracy: 0.4190\n",
            "Epoch 244/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0734 - accuracy: 0.9806 - val_loss: 2.9621 - val_accuracy: 0.4290\n",
            "Epoch 245/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0709 - accuracy: 0.9809 - val_loss: 2.6487 - val_accuracy: 0.4710\n",
            "Epoch 246/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0676 - accuracy: 0.9821 - val_loss: 2.8871 - val_accuracy: 0.4510\n",
            "Epoch 247/500\n",
            "316/316 [==============================] - 12s 38ms/step - loss: 0.0650 - accuracy: 0.9827 - val_loss: 2.7577 - val_accuracy: 0.4550\n",
            "Epoch 248/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0701 - accuracy: 0.9813 - val_loss: 2.9616 - val_accuracy: 0.4320\n",
            "Epoch 249/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0710 - accuracy: 0.9812 - val_loss: 2.7257 - val_accuracy: 0.4820\n",
            "Epoch 250/500\n",
            "315/316 [============================>.] - ETA: 0s - loss: 0.0659 - accuracy: 0.9823\n",
            "Epoch 00250: saving model to /content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/training_1/cp-0250.ckpt\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0657 - accuracy: 0.9824 - val_loss: 2.8390 - val_accuracy: 0.4420\n",
            "Epoch 251/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0668 - accuracy: 0.9814 - val_loss: 2.2424 - val_accuracy: 0.5230\n",
            "Epoch 252/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0620 - accuracy: 0.9833 - val_loss: 2.9227 - val_accuracy: 0.4370\n",
            "Epoch 253/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0628 - accuracy: 0.9811 - val_loss: 2.8703 - val_accuracy: 0.4540\n",
            "Epoch 254/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0685 - accuracy: 0.9825 - val_loss: 2.7663 - val_accuracy: 0.4600\n",
            "Epoch 255/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0624 - accuracy: 0.9833 - val_loss: 3.0104 - val_accuracy: 0.4260\n",
            "Epoch 256/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0635 - accuracy: 0.9820 - val_loss: 2.4127 - val_accuracy: 0.4910\n",
            "Epoch 257/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0604 - accuracy: 0.9835 - val_loss: 2.6340 - val_accuracy: 0.4820\n",
            "Epoch 258/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0740 - accuracy: 0.9799 - val_loss: 2.9040 - val_accuracy: 0.4430\n",
            "Epoch 259/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0630 - accuracy: 0.9816 - val_loss: 3.2304 - val_accuracy: 0.3950\n",
            "Epoch 260/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0779 - accuracy: 0.9804 - val_loss: 2.4375 - val_accuracy: 0.5050\n",
            "Epoch 261/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0649 - accuracy: 0.9816 - val_loss: 2.7196 - val_accuracy: 0.4730\n",
            "Epoch 262/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0575 - accuracy: 0.9835 - val_loss: 2.9499 - val_accuracy: 0.4270\n",
            "Epoch 263/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0707 - accuracy: 0.9812 - val_loss: 2.5472 - val_accuracy: 0.4930\n",
            "Epoch 264/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0637 - accuracy: 0.9821 - val_loss: 2.9424 - val_accuracy: 0.4480\n",
            "Epoch 265/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0630 - accuracy: 0.9839 - val_loss: 2.6636 - val_accuracy: 0.4620\n",
            "Epoch 266/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0598 - accuracy: 0.9830 - val_loss: 2.8643 - val_accuracy: 0.4550\n",
            "Epoch 267/500\n",
            "316/316 [==============================] - 13s 40ms/step - loss: 0.0695 - accuracy: 0.9826 - val_loss: 2.8118 - val_accuracy: 0.4590\n",
            "Epoch 268/500\n",
            "316/316 [==============================] - 12s 39ms/step - loss: 0.0684 - accuracy: 0.9811 - val_loss: 3.2601 - val_accuracy: 0.3940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-a05174b7f4ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           callbacks=[cp_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1086\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[1;32m   1087\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_recreate_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m           \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    397\u001b[0m       dataset = _OptimizeDataset(dataset, graph_rewrites.enabled,\n\u001b[1;32m    398\u001b[0m                                  \u001b[0mgraph_rewrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                                  graph_rewrites.default, graph_rewrite_configs)\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;31m# (4) Apply stats aggregator options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, optimization_configs)\u001b[0m\n\u001b[1;32m   4581\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations_default\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4582\u001b[0m         \u001b[0moptimization_configs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimization_configs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4583\u001b[0;31m         **self._flat_structure)\n\u001b[0m\u001b[1;32m   4584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4585\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_OptimizeDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset_v2\u001b[0;34m(input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   4023\u001b[0m         \u001b[0moptimizations_disabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4024\u001b[0m         \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_shapes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimization_configs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4025\u001b[0;31m         optimization_configs)\n\u001b[0m\u001b[1;32m   4026\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4027\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr85Tx_QWBQz"
      },
      "source": [
        "model.save('/content/drive/MyDrive/ML-DeepFakes-Detection/saved_model/run1.h5',save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rJ4PMMDDrjt"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data=val_data,\n",
        "          batch_size=32,\n",
        "          epochs=1000,  \n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zta1OsNoIGpW"
      },
      "source": [
        "model.fit(train_dataset,\n",
        "          validation_data=val_data,\n",
        "          batch_size=32,\n",
        "          epochs=1000,  \n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uycI4YE0A8gp"
      },
      "source": [
        "Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w6wyjnNA_gT",
        "outputId": "a043a1c0-dc08-499c-cb9f-107e36355fbd"
      },
      "source": [
        "with open('/content/video_data/fake1', 'rb') as f:\n",
        "    new_array = pickle.load(f)\n",
        "f.close()\n",
        "new_array=new_array[1:,:,:,:]\n",
        "x=np.array([1,0])\n",
        "print(new_array.shape)\n",
        "new_label=np.zeros((len(new_array)))\n",
        "print(new_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(300, 100, 100, 3)\n",
            "(300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y_OyR4iMY5t"
      },
      "source": [
        "test_labels=np.hstack([new_label])\n",
        "l=tf.keras.utils.to_categorical(test_labels, num_classes=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv2ptudmBbNb",
        "outputId": "f985d9a7-4ee0-4e00-fa58-dc237f809700"
      },
      "source": [
        "tensor=tf.convert_to_tensor(new_array)\n",
        "label=tf.convert_to_tensor(l)\n",
        "model.evaluate(tensor,label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 1s 52ms/step - loss: 4.9303e-07 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.930301997774222e-07, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bahZQXR4BvbG"
      },
      "source": [
        "model(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YG3t23tNb4E"
      },
      "source": [
        "**Testing on a random video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtFjj7pHP3Pp"
      },
      "source": [
        "import dlib\n",
        "from google.colab.patches import cv2_imshow\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZINxv_EJIRl"
      },
      "source": [
        "#video is fake. Lets see how model predicts\n",
        "!mkdir test-vid\n",
        "! cp /content/drive/MyDrive/ML-DeepFakes-Detection/Kaggle_Dataset/extracted/dfdc_train_part_18/baeajscskm.mp4 /content/test-vid/fake.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqxX_zdYOzzI"
      },
      "source": [
        "fake_vid=np.zeros((1,100,100,3))\n",
        "  #dir= directory + str(i) + '.mp4'\n",
        "  #print(dir)  \n",
        "  #fake_vid=video_to_file(dir, fake_vid)\n",
        "dir='/content/test-vid/fake.mp4'\n",
        "video_cap=cv2.VideoCapture(dir)\n",
        "while(video_cap.isOpened()):\n",
        "  ret,frame=video_cap.read()\n",
        "  if (ret==False):\n",
        "    break\n",
        "  face = detector(frame, 1)\n",
        "  if (len(face)):\n",
        "    face=face[0]\n",
        "    crop_img=frame[face.top():face.bottom(),face.left():face.right()]\n",
        "    crop_img=cv2.resize(crop_img,(100,100))\n",
        "      #cv2_imshow(crop_img)\n",
        "    crop_img = np.array(crop_img)\n",
        "    cropped = np.expand_dims(crop_img, axis=0)\n",
        "    fake_vid=np.append(fake_vid, cropped, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPb26ECvQCJ-",
        "outputId": "469a8e0e-5298-4ce4-e3cf-12b3393345f8"
      },
      "source": [
        "new_array=fake_vid[1:,:,:,:]\n",
        "x=np.array([1,0])\n",
        "print(new_array.shape)\n",
        "new_label=np.zeros((len(new_array)))\n",
        "print(new_label.shape)\n",
        "\n",
        "test_labels=np.hstack([new_label])\n",
        "l=tf.keras.utils.to_categorical(test_labels, num_classes=2)\n",
        "tensor=tf.convert_to_tensor(new_array)\n",
        "label=tf.convert_to_tensor(l)\n",
        "model.evaluate(tensor,label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(293, 100, 100, 3)\n",
            "(293,)\n",
            "10/10 [==============================] - 1s 54ms/step - loss: 1.8945 - accuracy: 0.6792\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8944752216339111, 0.6791808605194092]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1vc0eieR2Yx"
      },
      "source": [
        "model(tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pj1o571FR_A1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}